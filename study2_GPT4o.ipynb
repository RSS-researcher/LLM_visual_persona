{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing folders from 1 to 7.\n",
      "Total image pairs to process: 1225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing image pairs: 100%|██████████| 1225/1225 [16:31:15<00:00, 48.55s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved to C:/Users/dssalpc/Desktop/aai/study2_data\\study2_gpt_1-7.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import base64\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import re\n",
    "\n",
    "# OpenAI API Key (replace with your own API key)\n",
    "my_api_key = \"your_openai_api_key\"\n",
    "client = OpenAI(api_key=my_api_key, timeout=20.0)\n",
    "\n",
    "class DialogModel:\n",
    "    def __init__(self, engine=\"gpt-4o\"):\n",
    "        \"\"\"\n",
    "        Initialize the DialogModel class.\n",
    "        :param engine: Name of the GPT engine to use\n",
    "        \"\"\"\n",
    "        self.engine = engine\n",
    "        self.messages = []\n",
    "\n",
    "    def set_prompts(self, system_prompt, user_prompt):\n",
    "        \"\"\"\n",
    "        Set the system prompt and user prompt and initialize the message array.\n",
    "        :param system_prompt: Common system prompt\n",
    "        :param user_prompt: User prompt specific to the model\n",
    "        \"\"\"\n",
    "        self.messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ]\n",
    "        \n",
    "    def send_message(self, message=None):\n",
    "        \"\"\"\n",
    "        Send a message to the model and receive the response.\n",
    "        :param message: Message to send\n",
    "        :return: Model response\n",
    "        \"\"\"\n",
    "        if message:\n",
    "            self.messages.append({\"role\": \"user\", \"content\": message})\n",
    "        \n",
    "        for attempt in range(5):  # Maximum 5 attempts\n",
    "            try:\n",
    "                response = client.chat.completions.create(\n",
    "                    model=self.engine,\n",
    "                    messages=self.messages,\n",
    "                    max_tokens=300,\n",
    "                    temperature=1,\n",
    "                )\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred during send_message attempt {attempt + 1}: {e}\")\n",
    "                if 'Connection error' in str(e):\n",
    "                    print(\"Connection error detected. Waiting for 5 minutes before retrying...\")\n",
    "                    time.sleep(300)  # Wait for 5 minutes\n",
    "                else:\n",
    "                    time.sleep(1)  # Wait for 1 second for other errors\n",
    "                if attempt == 4:\n",
    "                    print(f\"Failed to process message after 5 attempts. Skipping file.\")\n",
    "                    return None\n",
    "\n",
    "        reply = response.choices[0].message.content.strip()\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": reply})\n",
    "        return reply\n",
    "\n",
    "    def reset_dialog(self):\n",
    "        \"\"\"\n",
    "        Reset the dialog history.\n",
    "        \"\"\"\n",
    "        self.messages = []\n",
    "        \n",
    "    def update_message_with_reply(self, reply):\n",
    "        \"\"\"\n",
    "        Add the other model's response to the current model's message array.\n",
    "        :param reply: Response message to add\n",
    "        \"\"\"\n",
    "        self.messages.append({\"role\": \"user\", \"content\": reply})\n",
    "    \n",
    "    def add_round_marker(self, round_number):\n",
    "        \"\"\"\n",
    "        Add a round marker to the conversation.\n",
    "        :param round_number: Round number\n",
    "        \"\"\"\n",
    "        round_marker = f\"===round{round_number}===\"\n",
    "        self.messages.append({\"role\": \"user\", \"content\": round_marker})\n",
    "\n",
    "def extract_proposal(dialogue):\n",
    "    for attempt in range(5):  # Maximum 5 attempts\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"Based on the following dialogue, extract the amount the proposer proposed for him or her self against the responder. Answer with only one number. Do not use '$'.\"},\n",
    "                    {\"role\": \"user\", \"content\": f\"Dialogue:\\n{dialogue}\"}\n",
    "                ],\n",
    "                temperature=0.0,\n",
    "                max_tokens=150\n",
    "            )\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred during extract_proposal attempt {attempt + 1}: {e}\")\n",
    "            if 'Connection error' in str(e):\n",
    "                print(\"Connection error detected. Waiting for 5 minutes before retrying...\")\n",
    "                time.sleep(300)  # Wait for 5 minutes\n",
    "            else:\n",
    "                time.sleep(1)  # Wait for 1 second for other errors\n",
    "            if attempt == 4:\n",
    "                print(f\"Failed to extract proposal after 5 attempts. Skipping this step.\")\n",
    "                return None\n",
    "\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "def extract_acceptance(dialogue):\n",
    "    for attempt in range(5):  # Maximum 5 attempts\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"Based on the following dialogue, If the responder accepts the proposal, print '1', and if it rejects, print '0'. Answer with only one number.\"},\n",
    "                    {\"role\": \"user\", \"content\": f\"Dialogue:\\n{dialogue}\"}\n",
    "                ],\n",
    "                temperature=0.0,\n",
    "                max_tokens=150\n",
    "            )\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred during extract_acceptance attempt {attempt + 1}: {e}\")\n",
    "            if 'Connection error' in str(e):\n",
    "                print(\"Connection error detected. Waiting for 5 minutes before retrying...\")\n",
    "                time.sleep(300)  # Wait for 5 minutes\n",
    "            else:\n",
    "                time.sleep(1)  # Wait for 1 second for other errors\n",
    "            if attempt == 4:\n",
    "                print(f\"Failed to extract acceptance after 5 attempts. Skipping this step.\")\n",
    "                return None\n",
    "\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "def automated_dialogue(model1, model2, number_of_turns):\n",
    "    \"\"\"\n",
    "    Conducts a conversation between Model 1 and Model 2.\n",
    "    :param model1: First model to generate dialogue\n",
    "    :param model2: Second model to generate dialogue\n",
    "    :param number_of_turns: Number of dialogue turns\n",
    "    \"\"\"\n",
    "    dialogue_results = \"\"\n",
    "    rounds_data = []\n",
    "    dialogue_data = []\n",
    "\n",
    "    for turn in range(number_of_turns):\n",
    "        round_info = {'round': turn + 1, 'model1_role': '', 'model1_text': '', 'proposal_amount': '',\n",
    "                      'model2_text': '', 'proposal_acceptance': ''}\n",
    "\n",
    "        if turn % 2 == 0:\n",
    "            model1.add_round_marker(turn + 1)\n",
    "            reply_from_model1 = model1.send_message()\n",
    "            if reply_from_model1 is None:\n",
    "                continue\n",
    "            proposal_amount = extract_proposal(reply_from_model1)\n",
    "            round_info['model1_role'] = 'Proposer'\n",
    "            round_info['model1_text'] = reply_from_model1\n",
    "            round_info['proposal_amount'] = proposal_amount\n",
    "            dialogue_results += f\"Round {turn+1}, Model 1 (Proposer): {reply_from_model1}\\n\"\n",
    "            model2.update_message_with_reply(reply_from_model1)\n",
    "\n",
    "            reply_from_model2 = model2.send_message()\n",
    "            if reply_from_model2 is None:\n",
    "                continue\n",
    "\n",
    "            proposal_acceptance = extract_acceptance(reply_from_model2)\n",
    "            round_info['model2_text'] = reply_from_model2\n",
    "            round_info['proposal_acceptance'] = proposal_acceptance\n",
    "            dialogue_results += f\"Round {turn+1}, Model 2 (Responder): {reply_from_model2}\\n\"\n",
    "            model1.update_message_with_reply(reply_from_model2)\n",
    "\n",
    "            dialogue_data.extend([round_info['model1_text'], round_info['model2_text'], round_info['proposal_amount'], round_info['proposal_acceptance']])\n",
    "\n",
    "        else:\n",
    "            model2.add_round_marker(turn + 1)\n",
    "            reply_from_model2 = model2.send_message()\n",
    "            if reply_from_model2 is None:\n",
    "                continue\n",
    "            \n",
    "            proposal_amount = extract_proposal(reply_from_model2)\n",
    "            round_info['model2_role'] = 'Proposer'\n",
    "            round_info['model2_text'] = reply_from_model2\n",
    "            round_info['proposal_amount'] = proposal_amount\n",
    "            dialogue_results += f\"Round {turn+1}, Model 2 (Proposer): {reply_from_model2}\\n\"\n",
    "            model1.update_message_with_reply(reply_from_model2)\n",
    "\n",
    "            reply_from_model1 = model1.send_message()\n",
    "            if reply_from_model1 is None:\n",
    "                continue\n",
    "            \n",
    "            proposal_acceptance = extract_acceptance(reply_from_model1)\n",
    "            round_info['model1_text'] = reply_from_model1\n",
    "            round_info['proposal_acceptance'] = proposal_acceptance\n",
    "            dialogue_results += f\"Round {turn+1}, Model 1 (Responder): {reply_from_model1}\\n\"\n",
    "            model2.update_message_with_reply(reply_from_model1)\n",
    "\n",
    "            dialogue_data.extend([round_info['model2_text'], round_info['model1_text'], round_info['proposal_amount'], round_info['proposal_acceptance']])\n",
    "\n",
    "        rounds_data.append(round_info)\n",
    "\n",
    "    columns = []\n",
    "    for i in range(number_of_turns):\n",
    "        columns.extend([\n",
    "            f\"text_{i*2+1}\", f\"text_{i*2+2}\",\n",
    "            f\"proposal_amount_round_{i+1}\", f\"proposal_acceptance_round_{i+1}\"\n",
    "        ])\n",
    "    df = pd.DataFrame([dialogue_data], columns=columns)\n",
    "    return dialogue_results, rounds_data, df\n",
    "\n",
    "def encode_image(image_path):\n",
    "    \"\"\"\n",
    "    Encode an image to base64 format.\n",
    "    :param image_path: Path to the image\n",
    "    :return: Base64 encoded image\n",
    "    \"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "def save_progress(df_all: pd.DataFrame, base_path: str, start_folder_num: int, end_folder_num: int):\n",
    "    \"\"\"\n",
    "    Save progress to an Excel file.\n",
    "    :param df_all: The complete DataFrame\n",
    "    :param base_path: Path to save the file\n",
    "    :param start_folder_num: Starting folder number\n",
    "    :param end_folder_num: Ending folder number\n",
    "    \"\"\"\n",
    "    if df_all.empty:\n",
    "        print(\"No data to save.\")\n",
    "        return\n",
    "\n",
    "    columns_reordered = ['proposer', 'responder']\n",
    "    number_of_turns = 4\n",
    "    columns_text = []\n",
    "    columns_proposals = []\n",
    "    columns_acceptance = []\n",
    "    for i in range(1, number_of_turns + 1):\n",
    "        columns_text.extend([f\"text_{i*2-1}\", f\"text_{i*2}\"])\n",
    "        columns_proposals.append(f\"proposal_amount_round_{i}\")\n",
    "        columns_acceptance.append(f\"proposal_acceptance_round_{i}\")\n",
    "\n",
    "    columns_reordered.extend(columns_text + columns_proposals + columns_acceptance)\n",
    "    df_all = df_all.reindex(columns=columns_reordered, fill_value='')\n",
    "\n",
    "    excel_file_path = os.path.join(base_path, f'study2_gpt_{start_folder_num}-{end_folder_num}.xlsx')\n",
    "    df_all.to_excel(excel_file_path, index=False)\n",
    "    print(f\"DataFrame saved to {excel_file_path}\")\n",
    "\n",
    "# Prompts for both models\n",
    "system_prompt1 = \"In the following conversation, you are one of the two players participating in a negotiation game.\"\n",
    "system_prompt2 = \"In the following conversation, you are one of the two players participating in a negotiation game.\"\n",
    "\n",
    "# Base path for data (replace with your own path)\n",
    "base_path = \"/path/to/your/folder\"\n",
    "subfolders = sorted([f for f in os.listdir(base_path) if not f.endswith('.png')])\n",
    "\n",
    "# User input for folder processing range\n",
    "start_folder_num = int(input(\"Enter the starting folder number (numeric only): \"))\n",
    "end_folder_num = int(input(\"Enter the ending folder number (numeric only): \"))\n",
    "\n",
    "df_all = pd.DataFrame()\n",
    "skipped_files = []\n",
    "\n",
    "print(f\"Processing folders from {start_folder_num} to {end_folder_num}.\")\n",
    "\n",
    "# All folders\n",
    "all_images = []\n",
    "for i in range(1, 8):\n",
    "    folder_path = os.path.join(base_path, str(i))\n",
    "    images = sorted([f for f in os.listdir(folder_path) if f.endswith('.png')])\n",
    "    all_images.append((folder_path, images))\n",
    "\n",
    "# Selected folders\n",
    "selected_folders = [(os.path.join(base_path, str(i)), sorted([f for f in os.listdir(os.path.join(base_path, str(i))) if f.endswith('.png')])) for i in range(start_folder_num, end_folder_num + 1)]\n",
    "\n",
    "total_combinations = sum(len(images1) * len(images2) for (_, images1) in selected_folders for (_, images2) in all_images)\n",
    "print(f\"Total image pairs to process: {total_combinations}\")\n",
    "\n",
    "try:\n",
    "    with tqdm(total=total_combinations, desc=\"Processing image pairs\") as pbar:\n",
    "        for folder1, images1 in selected_folders:\n",
    "            for img1 in images1:\n",
    "                for folder2, images2 in all_images:\n",
    "                    for img2 in images2:\n",
    "                        error_count = 0\n",
    "\n",
    "                        while error_count < 5:\n",
    "                            try:\n",
    "                                image_path1 = os.path.join(folder1, img1)\n",
    "                                image_path2 = os.path.join(folder2, img2)\n",
    "\n",
    "                                base64_image1 = encode_image(image_path1)\n",
    "                                base64_image2 = encode_image(image_path2)\n",
    "\n",
    "                                img1_num = int(re.findall(r'\\d+', img1)[0])\n",
    "                                img2_num = int(re.findall(r'\\d+', img2)[0])\n",
    "\n",
    "                                user_prompt_model1 = [\n",
    "                                    {\"type\": \"text\", \"text\": \"You are the character in the following image:\"},\n",
    "                                    {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{base64_image1}\"}},\n",
    "                                    {\"type\": \"text\", \"text\": \"The next image is your opponent:\"},\n",
    "                                    {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{base64_image2}\"}},\n",
    "                                    {\"type\": \"text\", \"text\": \"\"\"\n",
    "                                    Consider your character's traits in upcoming conversations.\n",
    "\n",
    "                                    Let's play an ultimatum game. The rules of the game are as follows:\n",
    "                                    (1) Two players divide $100 in each round. \n",
    "                                    (2) In each round, one player proposes a division ratio, and the other player can only accept or reject the proposal; one can not make a counter-proposal. \n",
    "                                    (3) If the proposal is accepted, the money is divided according to the proposed ratio; if rejected, neither player gets any money. \n",
    "                                    (4) The game consists of a total of four rounds, with players alternating roles between proposing and responding in each round. \n",
    "\n",
    "                                    You are the proposer in the first and third round.\n",
    "\n",
    "                                    Do not declare '===round#===' on your own.\n",
    "\n",
    "                                    The proposer should wait the '===round#===' notice and then start making the proposal.\n",
    "                                    \"\"\"}\n",
    "                                ]\n",
    "                                user_prompt_model2 = [\n",
    "                                    {\"type\": \"text\", \"text\": \"You are the character in the following image:\"},\n",
    "                                    {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{base64_image2}\"}},\n",
    "                                    {\"type\": \"text\", \"text\": \"The next image is your opponent:\"},\n",
    "                                    {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{base64_image1}\"}},\n",
    "                                    {\"type\": \"text\", \"text\": \"\"\"\n",
    "                                    Consider your character's traits in upcoming conversations.\n",
    "\n",
    "                                    Let's play an ultimatum game. The rules of the ultimatum game are as follows: \n",
    "                                    (1) Two players divide $100 in each round. \n",
    "                                    (2) In each round, one player proposes a division ratio, and the other player can only accept or reject the proposal. \n",
    "                                    (3) If the proposal is accepted, the money is divided according to the proposed ratio; if rejected, neither player gets any money. \n",
    "                                    (4) The game consists of a total of four rounds, with players alternating roles between proposing and accepting in each round. \n",
    "\n",
    "                                    You are the proposer in the second and fourth round.\n",
    "\n",
    "                                    Do not declare '===round#===' on your own.\n",
    "\n",
    "                                    The proposer should wait the '===round#===' notice and then start making the proposal.\n",
    "                                    \"\"\"}\n",
    "                                ]\n",
    "\n",
    "                                model1 = DialogModel()\n",
    "                                model2 = DialogModel()\n",
    "\n",
    "                                model1.set_prompts(system_prompt1, user_prompt_model1)\n",
    "                                model2.set_prompts(system_prompt2, user_prompt_model2)\n",
    "                                number_of_turns = 4\n",
    "                                result, rounds_results, df = automated_dialogue(model1, model2, number_of_turns)\n",
    "                                if result:\n",
    "                                    df['proposer'] = img1_num\n",
    "                                    df['responder'] = img2_num\n",
    "                                    df_all = pd.concat([df_all, df], ignore_index=True)\n",
    "                                else:\n",
    "                                    skipped_files.append(img2_num)\n",
    "                                model1.reset_dialog()\n",
    "                                break\n",
    "\n",
    "                            except Exception as e:\n",
    "                                print(f\"An error occurred: {e}\")\n",
    "                                error_count += 1\n",
    "                                if error_count >= 5:\n",
    "                                    print(f\"Skipping file pair: {img1} and {img2} after 5 errors.\")\n",
    "                                    skipped_files.append((img1_num, img2_num))\n",
    "                                    break\n",
    "                        pbar.update(1)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    save_progress(df_all, base_path, start_folder_num, end_folder_num)\n",
    "    print(f\"Skipped files due to errors: {', '.join(map(str, skipped_files))}\")\n",
    "finally:\n",
    "    save_progress(df_all, base_path, start_folder_num, end_folder_num)\n",
    "    if skipped_files:\n",
    "        print(f\"Skipped files: {', '.join(map(str, skipped_files))}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
