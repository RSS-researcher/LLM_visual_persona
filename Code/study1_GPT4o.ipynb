{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1Round Propose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import re\n",
    "\n",
    "# OpenAI API Key (replace with your own API key)\n",
    "my_api_key = \"your_openai_api_key\"\n",
    "client = OpenAI(api_key=my_api_key, timeout=20.0)\n",
    "\n",
    "class DialogModel:\n",
    "    def __init__(self, engine=\"gpt-4o\"):\n",
    "        \"\"\"\n",
    "        Initialize the DialogModel class.\n",
    "        :param engine: Name of the GPT engine to use\n",
    "        \"\"\"\n",
    "        self.engine = engine\n",
    "        self.messages = []\n",
    "\n",
    "    def set_prompts(self, system_prompt, user_prompt):\n",
    "        \"\"\"\n",
    "        Set the system prompt and user prompt and initialize the message array.\n",
    "        :param system_prompt: Common system prompt\n",
    "        :param user_prompt: User prompt specific to the model\n",
    "        \"\"\"\n",
    "        self.messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ]\n",
    "        \n",
    "    def send_message(self, message=None):\n",
    "        \"\"\"\n",
    "        Send a message to the model and receive the response.\n",
    "        :param message: Message to send\n",
    "        :return: Model response\n",
    "        \"\"\"\n",
    "        if message:\n",
    "            self.messages.append({\"role\": \"user\", \"content\": message})\n",
    "        \n",
    "        for attempt in range(5):  # Maximum 5 attempts\n",
    "            try:\n",
    "                response = client.chat.completions.create(\n",
    "                    model=self.engine,\n",
    "                    messages=self.messages,\n",
    "                    max_tokens=300,\n",
    "                    temperature=1,\n",
    "                )\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred during send_message attempt {attempt + 1}: {e}\")\n",
    "                if 'Connection error' in str(e):\n",
    "                    print(\"Connection error detected. Waiting for 5 minutes before retrying...\")\n",
    "                    time.sleep(300)  # Wait for 5 minutes\n",
    "                else:\n",
    "                    time.sleep(1)  # Wait for 1 second for other errors\n",
    "                if attempt == 4:\n",
    "                    print(f\"Failed to process message after 5 attempts. Skipping file.\")\n",
    "                    return None\n",
    "\n",
    "        reply = response.choices[0].message.content.strip()\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": reply})\n",
    "        return reply\n",
    "\n",
    "    def reset_dialog(self):\n",
    "        \"\"\"\n",
    "        Reset the dialog history.\n",
    "        \"\"\"\n",
    "        self.messages = []\n",
    "        \n",
    "    def update_message_with_reply(self, reply):\n",
    "        \"\"\"\n",
    "        Add the other model's response to the current model's message array.\n",
    "        :param reply: Response message to add\n",
    "        \"\"\"\n",
    "        self.messages.append({\"role\": \"user\", \"content\": reply})\n",
    "    \n",
    "    def add_round_marker(self, round_number):\n",
    "        \"\"\"\n",
    "        Add a round marker to the conversation.\n",
    "        :param round_number: Round number\n",
    "        \"\"\"\n",
    "        round_marker = f\"===round{round_number}===\"\n",
    "        self.messages.append({\"role\": \"user\", \"content\": round_marker})\n",
    "\n",
    "def extract_proposal(dialogue):\n",
    "    for attempt in range(5):  # Maximum 5 attempts\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"Based on the following dialogue, extract the amount the proposer proposed for him or her self against the responder. Answer with only one number. Do not use '$'.\"},\n",
    "                    {\"role\": \"user\", \"content\": f\"Dialogue:\\n{dialogue}\"}\n",
    "                ],\n",
    "                temperature=0.0,\n",
    "                max_tokens=150\n",
    "            )\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred during extract_proposal attempt {attempt + 1}: {e}\")\n",
    "            if 'Connection error' in str(e):\n",
    "                print(\"Connection error detected. Waiting for 5 minutes before retrying...\")\n",
    "                time.sleep(300)  # Wait for 5 minutes\n",
    "            else:\n",
    "                time.sleep(1)  # Wait for 1 second for other errors\n",
    "            if attempt == 4:\n",
    "                print(f\"Failed to extract proposal after 5 attempts. Skipping this step.\")\n",
    "                return None\n",
    "\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "def extract_acceptance(dialogue):\n",
    "    for attempt in range(5):  # Maximum 5 attempts\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"Based on the following dialogue, If the responder accepts the proposal, print '1', and if it rejects, print '0'. Answer with only one number.\"},\n",
    "                    {\"role\": \"user\", \"content\": f\"Dialogue:\\n{dialogue}\"}\n",
    "                ],\n",
    "                temperature=0.0,\n",
    "                max_tokens=150\n",
    "            )\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred during extract_acceptance attempt {attempt + 1}: {e}\")\n",
    "            if 'Connection error' in str(e):\n",
    "                print(\"Connection error detected. Waiting for 5 minutes before retrying...\")\n",
    "                time.sleep(300)  # Wait for 5 minutes\n",
    "            else:\n",
    "                time.sleep(1)  # Wait for 1 second for other errors\n",
    "            if attempt == 4:\n",
    "                print(f\"Failed to extract acceptance after 5 attempts. Skipping this step.\")\n",
    "                return None\n",
    "\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "def automated_dialogue(model1, manual_responses, number_of_turns):\n",
    "    \"\"\"\n",
    "    Conducts a conversation between Model 1 and manual responses.\n",
    "    :param model1: Model to generate dialogue\n",
    "    :param manual_responses: Manual responses for the other model\n",
    "    :param number_of_turns: Number of dialogue turns\n",
    "    \"\"\"\n",
    "    dialogue_results = \"\"  # To store the entire dialogue\n",
    "    rounds_data = []  # To store data for each round\n",
    "    dialogue_data = []\n",
    "\n",
    "    for turn in range(number_of_turns):\n",
    "        model1.add_round_marker(turn + 1)\n",
    "        round_info = {'round': turn + 1, 'model1_role': '', 'model1_text': '', 'proposal_amount': '',\n",
    "                      'model2_text': '', 'proposal_acceptance': ''}\n",
    "\n",
    "        if turn % 2 == 0:\n",
    "            reply_from_model1 = model1.send_message()\n",
    "            if reply_from_model1 is None:\n",
    "                continue\n",
    "            proposal_amount = extract_proposal(reply_from_model1)\n",
    "            round_info['model1_role'] = 'Proposer'\n",
    "            round_info['model1_text'] = reply_from_model1\n",
    "            round_info['proposal_amount'] = proposal_amount\n",
    "            dialogue_results += f\"Round {turn+1}, Model 1 (Proposer): {reply_from_model1}\\n\"\n",
    "            model1.update_message_with_reply(manual_responses[turn])\n",
    "            proposal_acceptance = extract_acceptance(manual_responses[turn])\n",
    "            round_info['model2_text'] = manual_responses[turn]\n",
    "            round_info['proposal_acceptance'] = proposal_acceptance\n",
    "            dialogue_results += f\"Round {turn+1}, Model 2 (Responder): {manual_responses[turn]}\\n\"\n",
    "            dialogue_data.extend([round_info['model1_text'], round_info['model2_text']])\n",
    "        else:\n",
    "            model1.update_message_with_reply(manual_responses[turn])\n",
    "            proposal_amount = extract_proposal(manual_responses[turn])\n",
    "            round_info['model2_text'] = manual_responses[turn]\n",
    "            round_info['proposal_amount'] = proposal_amount\n",
    "            dialogue_results += f\"Round {turn+1}, Model 2 (Proposer): {manual_responses[turn]}\\n\"\n",
    "            reply_from_model1 = model1.send_message()\n",
    "            if reply_from_model1 is None:\n",
    "                continue\n",
    "            proposal_acceptance = extract_acceptance(reply_from_model1)\n",
    "            round_info['model1_role'] = 'Responder'\n",
    "            round_info['model1_text'] = reply_from_model1\n",
    "            round_info['proposal_acceptance'] = proposal_acceptance\n",
    "            dialogue_results += f\"Round {turn+1}, Model 1 (Responder): {reply_from_model1}\\n\"\n",
    "            dialogue_data.extend([round_info['model2_text'], round_info['model1_text']])\n",
    "\n",
    "        rounds_data.append(round_info)\n",
    "        dialogue_data.extend([round_info['proposal_amount'], round_info['proposal_acceptance']])\n",
    "\n",
    "    columns = []\n",
    "    for i in range(number_of_turns):\n",
    "        columns.extend([\n",
    "            f\"text_{i*2+1}\", f\"text_{i*2+2}\",\n",
    "            f\"proposal_amount_round_{i+1}\", f\"proposal_acceptance_round_{i+1}\"\n",
    "        ])\n",
    "    df = pd.DataFrame([dialogue_data], columns=columns)\n",
    "    return dialogue_results, rounds_data, df\n",
    "\n",
    "def encode_image(image_path):\n",
    "    \"\"\"\n",
    "    Encode an image to base64 format.\n",
    "    :param image_path: Path to the image\n",
    "    :return: Base64 encoded image\n",
    "    \"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "def save_progress(df_all: pd.DataFrame, base_path: str, start_file_num: int, end_file_num: int):\n",
    "    \"\"\"\n",
    "    Save progress to an Excel file.\n",
    "    :param df_all: The complete DataFrame\n",
    "    :param base_path: Path to save the file\n",
    "    :param start_file_num: Starting file number\n",
    "    :param end_file_num: Ending file number\n",
    "    \"\"\"\n",
    "    columns_reordered = ['image_file']\n",
    "    number_of_turns = 4  # Assuming a fixed number of turns\n",
    "    columns_text = []\n",
    "    columns_proposals = []\n",
    "    columns_acceptance = []\n",
    "    for i in range(1, number_of_turns + 1):\n",
    "        columns_text.extend([f\"text_{i*2-1}\", f\"text_{i*2}\"])\n",
    "        columns_proposals.append(f\"proposal_amount_round_{i}\")\n",
    "        columns_acceptance.append(f\"proposal_acceptance_round_{i}\")\n",
    "\n",
    "    columns_reordered.extend(columns_text + columns_proposals + columns_acceptance)\n",
    "    df_all = df_all[columns_reordered]\n",
    "\n",
    "    # Save DataFrame to Excel file\n",
    "    excel_file_path = os.path.join(base_path, f'study1_gpt_1round_{start_file_num}-{end_file_num}.xlsx')\n",
    "    df_all.to_excel(excel_file_path, index=False)\n",
    "    print(f\"DataFrame saved to {excel_file_path}\")\n",
    "\n",
    "# Example execution\n",
    "manual_responses = [\n",
    "    \"As the responder, I accept your proposal.\",\n",
    "    \"As the proposer, I suggest an even split, $50 for me and 50$ for you.\",\n",
    "    \"As the responder, I accept your proposal.\",\n",
    "    \"As the proposer, I suggest a division of $75 for me and $25 for you.\"\n",
    "]\n",
    "\n",
    "system_prompt1 = \"In the following conversation, you are one of the two players participating in a negotiation game.\"\n",
    "\n",
    "base_path = \"/path/to/your/folder\"\n",
    "\n",
    "# User input for file processing range\n",
    "start_file_num = int(input(\"Enter the starting file number (numeric only): \"))\n",
    "num_files_to_process = int(input(\"Enter the number of files to process: \"))\n",
    "end_file_num = start_file_num + num_files_to_process - 1\n",
    "\n",
    "# Function to extract number for sorting files numerically\n",
    "def extract_number(file_name):\n",
    "    match = re.search(r'(\\d+)', file_name)\n",
    "    return int(match.group(1)) if match else -1\n",
    "\n",
    "files = sorted([file for file in os.listdir(base_path) if file.endswith('.png') and int(file.split('.')[0]) >= start_file_num], key=extract_number)[:num_files_to_process]\n",
    "df_all = pd.DataFrame()\n",
    "skipped_files = []\n",
    "print(f\"Processing files from {start_file_num} to {end_file_num} (total {num_files_to_process} files).\")\n",
    "\n",
    "try:\n",
    "    # Use tqdm to show progress\n",
    "    for file in tqdm(files, desc=\"Processing files\"):\n",
    "        image_num = int(file.split('.')[0])\n",
    "        image_path = os.path.join(base_path, file)\n",
    "        base64_image = encode_image(image_path)\n",
    "        user_prompt_model1 = [\n",
    "            {\"type\": \"text\", \"text\": \"You are the character in the following image:\"},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{base64_image}\"}},\n",
    "            {\"type\": \"text\", \"text\": \"\"\"\n",
    "            Consider your character's traits in upcoming conversations.\n",
    "\n",
    "            Let's play an ultimatum game. The rules of the game are as follows: \n",
    "            (1) Two players divide $100 in each round. \n",
    "            (2) In each round, one player proposes a division ratio, and the other player can only accept or reject the proposal; one can not make a counter-proposal. \n",
    "            (3) If the proposal is accepted, the money is divided according to the proposed ratio; if rejected, neither player gets any money. \n",
    "            (4) The game consists of a total of four rounds, with players alternating roles between proposing and responding in each round. \n",
    "            \n",
    "            You are the proposer in the first and third round.\n",
    "            \n",
    "            Do not declare '===round#===' on your own.\n",
    "\n",
    "            The proposer should wait the '===round#===' notice and then start making the proposal.\n",
    "            \"\"\"}\n",
    "        ]\n",
    "        model1 = DialogModel()\n",
    "        model1.set_prompts(system_prompt1, user_prompt_model1)\n",
    "        number_of_turns = 4\n",
    "        result, rounds_results, df = automated_dialogue(model1, manual_responses, number_of_turns)\n",
    "        if result:\n",
    "            df['image_file'] = image_num  # Add image file name to DataFrame (numeric only)\n",
    "            df_all = pd.concat([df_all, df], ignore_index=True)\n",
    "        else:\n",
    "            skipped_files.append(file)\n",
    "        model1.reset_dialog()\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    save_progress(df_all, base_path, start_file_num, image_num)\n",
    "    print(f\"Skipped files due to errors: {', '.join(skipped_files)}\")\n",
    "finally:\n",
    "    save_progress(df_all, base_path, start_file_num, end_file_num)\n",
    "    if skipped_files:\n",
    "        print(f\"Skipped files: {', '.join(skipped_files)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2Round Propose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import re\n",
    "\n",
    "# OpenAI API Key (replace with your own API key)\n",
    "my_api_key = \"your_openai_api_key\"\n",
    "client = OpenAI(api_key=my_api_key, timeout=20.0)\n",
    "\n",
    "class DialogModel:\n",
    "    def __init__(self, engine=\"gpt-4o\"):\n",
    "        \"\"\"\n",
    "        Initialize the DialogModel class.\n",
    "        :param engine: Name of the GPT engine to use\n",
    "        \"\"\"\n",
    "        self.engine = engine\n",
    "        self.messages = []\n",
    "\n",
    "    def set_prompts(self, system_prompt, user_prompt):\n",
    "        \"\"\"\n",
    "        Set the system prompt and user prompt and initialize the message array.\n",
    "        :param system_prompt: Common system prompt\n",
    "        :param user_prompt: User prompt specific to the model\n",
    "        \"\"\"\n",
    "        self.messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ]\n",
    "        \n",
    "    def send_message(self, message=None):\n",
    "        \"\"\"\n",
    "        Send a message to the model and receive the response.\n",
    "        :param message: Message to send\n",
    "        :return: Model response\n",
    "        \"\"\"\n",
    "        if message:\n",
    "            self.messages.append({\"role\": \"user\", \"content\": message})\n",
    "        \n",
    "        for attempt in range(5):  # Maximum 5 attempts\n",
    "            try:\n",
    "                response = client.chat.completions.create(\n",
    "                    model=self.engine,\n",
    "                    messages=self.messages,\n",
    "                    max_tokens=300,\n",
    "                    temperature=1,\n",
    "                )\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred during send_message attempt {attempt + 1}: {e}\")\n",
    "                if 'Connection error' in str(e):\n",
    "                    print(\"Connection error detected. Waiting for 5 minutes before retrying...\")\n",
    "                    time.sleep(300)  # Wait for 5 minutes\n",
    "                else:\n",
    "                    time.sleep(1)  # Wait for 1 second for other errors\n",
    "                if attempt == 4:\n",
    "                    print(f\"Failed to process message after 5 attempts. Skipping file.\")\n",
    "                    return None\n",
    "\n",
    "        reply = response.choices[0].message.content.strip()\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": reply})\n",
    "        return reply\n",
    "\n",
    "    def reset_dialog(self):\n",
    "        \"\"\"\n",
    "        Reset the dialog history.\n",
    "        \"\"\"\n",
    "        self.messages = []\n",
    "        \n",
    "    def update_message_with_reply(self, reply):\n",
    "        \"\"\"\n",
    "        Add the other model's response to the current model's message array.\n",
    "        :param reply: Response message to add\n",
    "        \"\"\"\n",
    "        self.messages.append({\"role\": \"user\", \"content\": reply})\n",
    "    \n",
    "    def add_round_marker(self, round_number):\n",
    "        \"\"\"\n",
    "        Add a round marker to the conversation.\n",
    "        :param round_number: Round number\n",
    "        \"\"\"\n",
    "        round_marker = f\"===round{round_number}===\"\n",
    "        self.messages.append({\"role\": \"user\", \"content\": round_marker})\n",
    "\n",
    "def extract_proposal(dialogue):\n",
    "    for attempt in range(5):  # Maximum 5 attempts\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"Based on the following dialogue, extract the amount the proposer proposed for him or her self against the responder. Answer with only one number. Do not use '$'.\"},\n",
    "                    {\"role\": \"user\", \"content\": f\"Dialogue:\\n{dialogue}\"}\n",
    "                ],\n",
    "                temperature=0.0,\n",
    "                max_tokens=150\n",
    "            )\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred during extract_proposal attempt {attempt + 1}: {e}\")\n",
    "            if 'Connection error' in str(e):\n",
    "                print(\"Connection error detected. Waiting for 5 minutes before retrying...\")\n",
    "                time.sleep(300)  # Wait for 5 minutes\n",
    "            else:\n",
    "                time.sleep(1)  # Wait for 1 second for other errors\n",
    "            if attempt == 4:\n",
    "                print(f\"Failed to extract proposal after 5 attempts. Skipping this step.\")\n",
    "                return None\n",
    "\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "def extract_acceptance(dialogue):\n",
    "    for attempt in range(5):  # Maximum 5 attempts\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"Based on the following dialogue, If the responder accepts the proposal, print '1', and if it rejects, print '0'. Answer with only one number.\"},\n",
    "                    {\"role\": \"user\", \"content\": f\"Dialogue:\\n{dialogue}\"}\n",
    "                ],\n",
    "                temperature=0.0,\n",
    "                max_tokens=150\n",
    "            )\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred during extract_acceptance attempt {attempt + 1}: {e}\")\n",
    "            if 'Connection error' in str(e):\n",
    "                print(\"Connection error detected. Waiting for 5 minutes before retrying...\")\n",
    "                time.sleep(300)  # Wait for 5 minutes\n",
    "            else:\n",
    "                time.sleep(1)  # Wait for 1 second for other errors\n",
    "            if attempt == 4:\n",
    "                print(f\"Failed to extract acceptance after 5 attempts. Skipping this step.\")\n",
    "                return None\n",
    "\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "def automated_dialogue(model1, manual_responses, number_of_turns):\n",
    "    \"\"\"\n",
    "    Conducts a conversation between Model 1 and manual responses.\n",
    "    :param model1: Model to generate dialogue\n",
    "    :param manual_responses: Manual responses for the other model\n",
    "    :param number_of_turns: Number of dialogue turns\n",
    "    \"\"\"\n",
    "    dialogue_results = \"\"  # To store the entire dialogue\n",
    "    rounds_data = []  # To store data for each round\n",
    "    dialogue_data = []\n",
    "\n",
    "    for turn in range(number_of_turns):\n",
    "        model1.add_round_marker(turn + 1)\n",
    "        round_info = {'round': turn + 1, 'model1_role': '', 'model1_text': '', 'proposal_amount': '',\n",
    "                      'model2_text': '', 'proposal_acceptance': ''}\n",
    "\n",
    "        if turn % 2 == 0:\n",
    "            # Model 2 (manual_responses) is the proposer in even rounds\n",
    "            model1.update_message_with_reply(manual_responses[turn])\n",
    "            proposal_amount = extract_proposal(manual_responses[turn])\n",
    "            round_info['model2_text'] = manual_responses[turn]\n",
    "            round_info['proposal_amount'] = proposal_amount\n",
    "            dialogue_results += f\"Round {turn+1}, Model 2 (Proposer): {manual_responses[turn]}\\n\"\n",
    "            reply_from_model1 = model1.send_message()\n",
    "            if reply_from_model1 is None:\n",
    "                continue\n",
    "            proposal_acceptance = extract_acceptance(reply_from_model1)\n",
    "            round_info['model1_role'] = 'Responder'\n",
    "            round_info['model1_text'] = reply_from_model1\n",
    "            round_info['proposal_acceptance'] = proposal_acceptance\n",
    "            dialogue_results += f\"Round {turn+1}, Model 1 (Responder): {reply_from_model1}\\n\"\n",
    "            dialogue_data.extend([round_info['model2_text'], round_info['model1_text']])\n",
    "        else:\n",
    "            # Model 1 is the proposer in odd rounds\n",
    "            reply_from_model1 = model1.send_message()\n",
    "            if reply_from_model1 is None:\n",
    "                continue\n",
    "            proposal_amount = extract_proposal(reply_from_model1)\n",
    "            round_info['model1_role'] = 'Proposer'\n",
    "            round_info['model1_text'] = reply_from_model1\n",
    "            round_info['proposal_amount'] = proposal_amount\n",
    "            dialogue_results += f\"Round {turn+1}, Model 1 (Proposer): {reply_from_model1}\\n\"\n",
    "            model1.update_message_with_reply(manual_responses[turn])\n",
    "            proposal_acceptance = extract_acceptance(manual_responses[turn])\n",
    "            round_info['model2_text'] = manual_responses[turn]\n",
    "            round_info['proposal_acceptance'] = proposal_acceptance\n",
    "            dialogue_results += f\"Round {turn+1}, Model 2 (Responder): {manual_responses[turn]}\\n\"\n",
    "            dialogue_data.extend([round_info['model1_text'], round_info['model2_text']])\n",
    "\n",
    "        rounds_data.append(round_info)\n",
    "        dialogue_data.extend([round_info['proposal_amount'], round_info['proposal_acceptance']])\n",
    "\n",
    "    columns = []\n",
    "    for i in range(number_of_turns):\n",
    "        columns.extend([\n",
    "            f\"text_{i*2+1}\", f\"text_{i*2+2}\",\n",
    "            f\"proposal_amount_round_{i+1}\", f\"proposal_acceptance_round_{i+1}\"\n",
    "        ])\n",
    "    df = pd.DataFrame([dialogue_data], columns=columns)\n",
    "    return dialogue_results, rounds_data, df\n",
    "\n",
    "def encode_image(image_path):\n",
    "    \"\"\"\n",
    "    Encode an image to base64 format.\n",
    "    :param image_path: Path to the image\n",
    "    :return: Base64 encoded image\n",
    "    \"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "def save_progress(df_all: pd.DataFrame, base_path: str, start_file_num: int, end_file_num: int):\n",
    "    \"\"\"\n",
    "    Save progress to an Excel file.\n",
    "    :param df_all: The complete DataFrame\n",
    "    :param base_path: Path to save the file\n",
    "    :param start_file_num: Starting file number\n",
    "    :param end_file_num: Ending file number\n",
    "    \"\"\"\n",
    "    columns_reordered = ['image_file']\n",
    "    number_of_turns = 4  # Assuming a fixed number of turns\n",
    "    columns_text = []\n",
    "    columns_proposals = []\n",
    "    columns_acceptance = []\n",
    "    for i in range(1, number_of_turns + 1):\n",
    "        columns_text.extend([f\"text_{i*2-1}\", f\"text_{i*2}\"])\n",
    "        columns_proposals.append(f\"proposal_amount_round_{i}\")\n",
    "        columns_acceptance.append(f\"proposal_acceptance_round_{i}\")\n",
    "\n",
    "    columns_reordered.extend(columns_text + columns_proposals + columns_acceptance)\n",
    "    df_all = df_all[columns_reordered]\n",
    "\n",
    "    # Save DataFrame to Excel file\n",
    "    excel_file_path = os.path.join(base_path, f'study1_gpt_2round_{start_file_num}-{end_file_num}.xlsx')\n",
    "    df_all.to_excel(excel_file_path, index=False)\n",
    "    print(f\"DataFrame saved to {excel_file_path}\")\n",
    "\n",
    "# Example execution\n",
    "manual_responses = [\n",
    "    \"As the proposer, I suggest an even split, $50 for me and $50 for you.\",\n",
    "    \"As the responder, I accept your proposal.\",\n",
    "    \"As the proposer, I suggest a division of $75 for me and $25 for you.\",\n",
    "    \"As the responder, I accept your proposal.\",\n",
    "]\n",
    "\n",
    "system_prompt1 = \"In the following conversation, you are one of the two players participating in a negotiation game.\"\n",
    "\n",
    "base_path = \"/path/to/your/folder\"\n",
    "# User input for file processing range\n",
    "start_file_num = int(input(\"Enter the starting file number (numeric only): \"))\n",
    "num_files_to_process = int(input(\"Enter the number of files to process: \"))\n",
    "end_file_num = start_file_num + num_files_to_process - 1\n",
    "\n",
    "# Function to extract number for sorting files numerically\n",
    "def extract_number(file_name):\n",
    "    match = re.search(r'(\\d+)', file_name)\n",
    "    return int(match.group(1)) if match else -1\n",
    "\n",
    "files = sorted([file for file in os.listdir(base_path) if file.endswith('.png') and int(file.split('.')[0]) >= start_file_num], key=extract_number)[:num_files_to_process]\n",
    "df_all = pd.DataFrame()\n",
    "skipped_files = []\n",
    "print(f\"Processing files from {start_file_num} to {end_file_num} (total {num_files_to_process} files).\")\n",
    "\n",
    "try:\n",
    "    # Use tqdm to show progress\n",
    "    for file in tqdm(files, desc=\"Processing files\"):\n",
    "        image_num = int(file.split('.')[0])\n",
    "        image_path = os.path.join(base_path, file)\n",
    "        base64_image = encode_image(image_path)\n",
    "        user_prompt_model1 = [\n",
    "            {\"type\": \"text\", \"text\": \"You are the character in the following image:\"},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{base64_image}\"}},\n",
    "            {\"type\": \"text\", \"text\": \"\"\"\n",
    "            Consider your character's traits in upcoming conversations.\n",
    "\n",
    "            Let's play an ultimatum game. The rules of the game are as follows: \n",
    "            (1) Two players divide $100 in each round. \n",
    "            (2) In each round, one player proposes a division ratio, and the other player can only accept or reject the proposal; one can not make a counter-proposal. \n",
    "            (3) If the proposal is accepted, the money is divided according to the proposed ratio; if rejected, neither player gets any money. \n",
    "            (4) The game consists of a total of four rounds, with players alternating roles between proposing and responding in each round. \n",
    "            \n",
    "            You are the proposer in the second and fourth round.\n",
    "            \n",
    "            Do not declare '===round#===' on your own.\n",
    "\n",
    "            The proposer should wait the '===round#===' notice and then start making the proposal.\n",
    "            \"\"\"}\n",
    "        ]\n",
    "        model1 = DialogModel()\n",
    "        model1.set_prompts(system_prompt1, user_prompt_model1)\n",
    "        number_of_turns = 4\n",
    "        result, rounds_results, df = automated_dialogue(model1, manual_responses, number_of_turns)\n",
    "        if result:\n",
    "            df['image_file'] = image_num  # Add image file name to DataFrame (numeric only)\n",
    "            df_all = pd.concat([df_all, df], ignore_index=True)\n",
    "        else:\n",
    "            skipped_files.append(file)\n",
    "        model1.reset_dialog()\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    save_progress(df_all, base_path, start_file_num, image_num)\n",
    "    print(f\"Skipped files due to errors: {', '.join(skipped_files)}\")\n",
    "finally:\n",
    "    save_progress(df_all, base_path, start_file_num, end_file_num)\n",
    "    if skipped_files:\n",
    "        print(f\"Skipped files: {', '.join(skipped_files)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "0.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
